{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUrM6Gml9qvd"
   },
   "source": [
    "감성 분석\n",
    "\n",
    "- 케라스의  GRU 모델을 이용한 IMDB 영화 리뷰 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xTEDO0t9-G6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcbvpwX4-U5M",
    "outputId": "d4a18713-bfb1-4658-b220-74ebc1e59a55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "17473536/17464789 [==============================] - 0s 0us/step\n",
      "(25000,)\n",
      "(25000,)\n",
      "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])\n",
      " list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "#kears에서 제공하는 IMDB 리뷰 데이터 불러오기\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000) #빈도수 상위 10000개 단어만 가져오기\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_train[:2]) #작은 값일 수록 자주 등장한 단어\n",
    "print(y_train[:2]) #0:부정, 1:긍정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dYRRo6-_ZTq",
    "outputId": "082dee3a-7ca4-41de-cf90-a26f4d4b0049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n",
      "None this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert None is an amazing actor and now the same being director None father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for None and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also None to the two little boy's that played the None of norman and paul they were just brilliant children are often left out of the None list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all "
     ]
    }
   ],
   "source": [
    "#인덱스 리스트를 다시 텍스트로 바꿔보기\n",
    "word_index = imdb.get_word_index()\n",
    "word_index2 = {v:k for k,v in word_index.items()} \n",
    "\n",
    "for word in X_train[0]:\n",
    "  print(word_index2.get(word-3), end=\" \") #0:padding, 1:시작, 2:없는단어 의미하는 인덱스-> word-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bm89rU7jDlDE"
   },
   "outputs": [],
   "source": [
    "#각 리뷰 길이 1000으로 맞춰주기\n",
    "X_train = pad_sequences(X_train, maxlen=1000) #초과하면 삭제, 부족하면 0으로 채우기\n",
    "X_test = pad_sequences(X_test, maxlen=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30OQAbeVGEmw"
   },
   "outputs": [],
   "source": [
    "#딥러닝 모델 생성\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 100))\n",
    "model.add(GRU(128)) \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CedVD6EQHfju",
    "outputId": "9b7347d6-b097-4a65-f211-4c277f061724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.4899 - acc: 0.7573\n",
      "Epoch 1: val_acc improved from -inf to 0.77320, saving model to my_model.h5\n",
      "313/313 [==============================] - 577s 2s/step - loss: 0.4899 - acc: 0.7573 - val_loss: 0.4704 - val_acc: 0.7732\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.3181 - acc: 0.8727\n",
      "Epoch 2: val_acc improved from 0.77320 to 0.87420, saving model to my_model.h5\n",
      "313/313 [==============================] - 569s 2s/step - loss: 0.3181 - acc: 0.8727 - val_loss: 0.3043 - val_acc: 0.8742\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.2362 - acc: 0.9083\n",
      "Epoch 3: val_acc improved from 0.87420 to 0.88820, saving model to my_model.h5\n",
      "313/313 [==============================] - 566s 2s/step - loss: 0.2362 - acc: 0.9083 - val_loss: 0.2867 - val_acc: 0.8882\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1924 - acc: 0.9269\n",
      "Epoch 4: val_acc did not improve from 0.88820\n",
      "313/313 [==============================] - 563s 2s/step - loss: 0.1924 - acc: 0.9269 - val_loss: 0.3881 - val_acc: 0.8742\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1486 - acc: 0.9457\n",
      "Epoch 5: val_acc improved from 0.88820 to 0.88920, saving model to my_model.h5\n",
      "313/313 [==============================] - 560s 2s/step - loss: 0.1486 - acc: 0.9457 - val_loss: 0.3606 - val_acc: 0.8892\n"
     ]
    }
   ],
   "source": [
    "#모델 학습\n",
    "mc = ModelCheckpoint('my_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True) #이전보다 검증 정확도가 높아지면 모델 저장\n",
    "history = model.fit(X_train, y_train, epochs=5, callbacks=[mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqc-XTYDIjnU",
    "outputId": "ab7f1577-4a31-4e26-c81a-327a04562938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 156s 199ms/step - loss: 0.3723 - acc: 0.8824\n",
      "정확도: 0.8823999762535095\n"
     ]
    }
   ],
   "source": [
    "#저장한 모델 로드\n",
    "loaded_model = load_model('my_model.h5')\n",
    "print(\"정확도:\",(loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-oYmTXaIynA",
    "outputId": "50fc55d4-915a-4db9-9118-5aa9a6c2e9b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 리뷰일 확률: 1.0024458169937134% \n"
     ]
    }
   ],
   "source": [
    "#실제 리뷰 긍정/부정 예측해보기\n",
    "import re\n",
    "\n",
    "#아케인 리뷰 출처: https://www.imdb.com/title/tt11126994/reviews?ref_=tt_urv\n",
    "\n",
    "#부정적 리뷰 예측\n",
    "\n",
    "#아케인 1점 리뷰\n",
    "bad_sentence = '''What the hell was that really wasted my time there. Everyone tries their best to do something and viola that jinx is there to ruin it all,can there be more annoying character than her wtf writing.'''\n",
    "\n",
    "bad_sentence = re.sub('[^\\w ]', '', bad_sentence).lower() #word(숫자, 알파벳, _)와 space만 추출\n",
    "\n",
    "encoded = []\n",
    "for word in bad_sentence.split():\n",
    "    if word in word_index and word_index[word] <= 10000:\n",
    "      encoded.append(word_index[word]+3)\n",
    "    else: \n",
    "      encoded.append(2) #사전에 없거나 10000이상인 경우, 2(None 의미하는 인덱스) 넣기\n",
    "\n",
    "pad_sequence = pad_sequences([encoded], maxlen=1000) \n",
    "score = float(loaded_model.predict(pad_sequence)) # 로드한 모델로 예측하기\n",
    "\n",
    "print(f\"긍정적인 리뷰일 확률: {score * 100}% \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "149oPopOkS9A",
    "outputId": "b128b95a-6d5c-45b9-de22-08e69805dc0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 리뷰일 확률: 97.97621965408325% \n"
     ]
    }
   ],
   "source": [
    "#긍정적 리뷰 예측\n",
    "\n",
    "#아케인 10점 리뷰\n",
    "good_sentence = '''So many positives i don't know where to start! This is unique, gripping probably won't happen again like this! Phenomenal. Art is an anomaly; i don't get how but i know it is reality.'''\n",
    "\n",
    "good_sentence = re.sub('[^\\w ]', '', good_sentence).lower() #word(숫자, 알파벳, _)와 space만 추출\n",
    "\n",
    "encoded = []\n",
    "for word in good_sentence.split():\n",
    "    if word in word_index and word_index[word] <= 10000:\n",
    "      encoded.append(word_index[word]+3)\n",
    "    else: \n",
    "      encoded.append(2) #사전에 없거나 10000이상인 경우, 2(None 의미하는 인덱스) 넣기\n",
    "\n",
    "pad_sequence = pad_sequences([encoded], maxlen=1000) \n",
    "score = float(loaded_model.predict(pad_sequence)) # 로드한 모델로 예측하기\n",
    "\n",
    "print(f\"긍정적인 리뷰일 확률: {score * 100}% \")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
